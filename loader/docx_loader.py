from langchain_community.document_loaders import Docx2txtLoader
from langchain_core.documents import Document
import re
import os

def load_and_clean_docx(file_path: str) -> list[Document]:
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"âŒ ÙØ§ÛŒÙ„ '{file_path}' Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")

    print(f"ğŸ“„ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„: {file_path}")
    loader = Docx2txtLoader(file_path)
    documents = loader.load()

    raw_text = documents[0].page_content

    cleaned_text = re.sub(r'www\.ketabesabz\.com', '', raw_text, flags=re.IGNORECASE)
    cleaned_text = re.sub(r'ØµÙØ­Ù‡[:\s]*\d+', '', cleaned_text)
    cleaned_text = re.sub(r'Ø¢Ø¯Ù…ÛŒØ§Ù† \d+ â€\d+â€', '', cleaned_text)
    cleaned_text = re.sub(r'\d+ #? ?Ø²ÙˆÛŒØ§ Ù‚Ù„ÛŒâ€ŒÙ¾ÙˆØ±', '', cleaned_text)
    cleaned_text = re.sub(r'\n\s*\n', '\n\n', cleaned_text)

    return [Document(page_content=cleaned_text)]
